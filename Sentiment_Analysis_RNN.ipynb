{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import Counter, OrderedDict\n",
    "import itertools\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deep-learning-v2-pytorch/sentiment-analysis-network/reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('deep-learning-v2-pytorch/sentiment-analysis-network/labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will recieve the imported reviews (ch by ch) and return \n",
    "def clean_text(text):\n",
    "    ''' This Function recieves reviews (ch by ch) and returns a list of\n",
    "    reviews without punctuation and stopwords'''\n",
    "    # remove punctuation\n",
    "    s = ''.join(ch.lower() for ch in text if ch not in punctuation)\n",
    "    \n",
    "    # separate each review and add to a list so that I have a list of reviews\n",
    "    separated_reviews = []\n",
    "\n",
    "    for review in s.split('\\n'):\n",
    "        review = ''.join(review)\n",
    "        separated_reviews.append(review)\n",
    "        \n",
    "        \n",
    "    # remove stopwords and return a list of reviews\n",
    "    clean_text = []\n",
    "    for review in separated_reviews:\n",
    "        review_no_stopwords = []\n",
    "        for word in review.split():\n",
    "            if word not in stopwords.words('english'):\n",
    "                review_no_stopwords.append(word)\n",
    "        clean_text.append(' '.join(review_no_stopwords))\n",
    "        \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each word to a number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = clean_text(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_copy = reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewEncoder:\n",
    "    def __init__(self):\n",
    "        self.__words_dict = {}\n",
    "        self.__indexer = 1\n",
    "    def encode(self, text):\n",
    "        encoded_review = []\n",
    "        words = text.split()\n",
    "        #print(words)\n",
    "        for word in words:\n",
    "            if word in self. __words_dict:\n",
    "                encoded_review.append(self.__words_dict[word])\n",
    "            else:\n",
    "                self.__words_dict[word] = self.__indexer\n",
    "                self.__indexer += 1\n",
    "                encoded_review.append(self.__words_dict[word])\n",
    "        return encoded_review\n",
    "    \n",
    "    def len_dict(self):\n",
    "        return len(self.__words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ReviewEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_reviews = []\n",
    "for review in reviews:\n",
    "    encoded_reviews.append(encoder.encode(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = encoder.len_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = encoder.encode(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to check for reviews with length zero and dropping them\n",
    "\n",
    "def drop_empty_reviews(text):\n",
    "    \n",
    "    full_reviews = []\n",
    "    \n",
    "    for index, review in enumerate(text):\n",
    "        if len(review) != 0:\n",
    "            full_reviews.append(review)\n",
    "            \n",
    "    return full_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = drop_empty_reviews(encoded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_truncation(encoded_review_list):\n",
    "    \n",
    "    padded_review = []\n",
    "    for review in encoded_review_list:\n",
    "        if len(review) < 200:\n",
    "            padding = 200 - len(review)\n",
    "            review = ([0]*padding + review)\n",
    "            padded_review.append(review)\n",
    "        elif len(review) > 200:\n",
    "            truncate = len(review) - 200\n",
    "            review = review[truncate:]\n",
    "            padded_review.append(review)\n",
    "        else:\n",
    "            padded_review.append(review)\n",
    "            \n",
    "    return padded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_reviews = padding_truncation(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "check = []\n",
    "for review in padded_reviews:\n",
    "    if len(review) < 200 or len(review) > 200:\n",
    "        check.append(review)\n",
    "print(len(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training, validation and testing sets\n",
    "\n",
    "training = int(len(padded_reviews) * 0.8)\n",
    "validation = int(training + len(padded_reviews)*0.1)\n",
    "\n",
    "train_x = np.array(padded_reviews[:training])\n",
    "train_y = np.array(encoded_labels[:training])\n",
    "\n",
    "val_x = np.array(padded_reviews[training:validation])\n",
    "val_y = np.array(encoded_labels[training:validation])\n",
    "\n",
    "test_x = np.array(padded_reviews[validation:])\n",
    "test_y = np.array(encoded_labels[validation:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_loader = DataLoader(dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    sampler=None,\n",
    "    batch_sampler=None,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    "    timeout=0,\n",
    "    worker_init_fn=None,\n",
    "    multiprocessing_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 200)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(train_x).long(), torch.from_numpy(train_y))\n",
    "valid_dataset = TensorDataset(torch.from_numpy(val_x).long(), torch.from_numpy(val_y))\n",
    "test_dataset = TensorDataset(torch.from_numpy(test_x).long(), torch.from_numpy(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=50, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing\n",
    "\n",
    "testing = DataLoader(dataset=train_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = next(iter(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in testing:\n",
    "    x = x.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,   601,\n",
       "          1921,   595, 11799,   387,  6645,  1735,  7818,  3193,    17,    98,\n",
       "          1275,  2224,  1454,  4142, 11800,    61,  2434,   413,   700,  2750,\n",
       "           988,  1205,  1222,  1358,   382, 11801,   397,   595,   356,    47,\n",
       "          1788, 11802,   148,   148,  7818,  3193,   339,   260,    57,   410,\n",
       "          1704,  1753,  8963,   200,   428,  1467,  1911,  1601,   163, 10219,\n",
       "         11803,  5251, 11792,  7837,  8019, 11792,  1344,   296, 11804,  6417,\n",
       "           721,   358,   251, 11805,  7015,    84, 11806,  5641,  9785,  2924,\n",
       "           629, 11807,  6680,  7226,  1711,   148,   148,   904,   366,  1065,\n",
       "           595,  7236,   163, 10219,   450,   374,   617,  1374,    54,  3138,\n",
       "           450,   200, 11808,  1501,  5251,    83, 11809,   910,    64,  2528,\n",
       "          1344,  6680,  6417,   721,   689,    53,   764,  1711,    64, 11810,\n",
       "           910,   802,   431,  1785,   527,   511,   100,  1250,  3042,   595,\n",
       "           970,   387,   253,   700,   867,  1483,   111,   950,  1908,  6722],\n",
       "        [  595,   904,  1664,  6821,  3422,   731,   376,   111,   524,  2471,\n",
       "           977,    90,   595,   100,   374,  2311,   725,  2152,   163,  5196,\n",
       "           763,  1446,   517,   450,   516,  3643,   731,  2471,   595,  4601,\n",
       "          3345,  4756,  2975,   493,   103,   231,   148,   148,  5588,  5589,\n",
       "          5196,  4530, 18484,   103,   260, 37569, 29899,   372,   405,   686,\n",
       "           595,  2975,   493,  3372,  2960,  1733,   200,  2771,  1818,   148,\n",
       "           148,  2292,  2224,  1754,   595,   125,   872,    25,  2479,   148,\n",
       "           148, 53456,   148,   148,  1235,   253,  1560,  3559,   151,   148,\n",
       "           148, 18484,  8668,   777,   603,  5196,  1486,   493,   148,   148,\n",
       "            50,  6249,   148,   148,   345,   408,   911,  3827,  1428,  1288,\n",
       "           148,   148,   163,   188,  1250,  1527,   950,   601, 11132,   872,\n",
       "           198,  4954,    17,  2876,   188,     6,  9556,  2095, 27357,  1162,\n",
       "          4335, 17919,   148,   148,  1912,   231,    66,  1560, 17919,  6263,\n",
       "           600,  2093, 27357,  8159,   148,   148,  1119,  1998,   486,   148,\n",
       "           148, 27477,   324, 17919,  2539, 17919,  2834,  6061, 27477, 17443,\n",
       "          1334,  1056,  2234,   153,   986,   447,  4663, 17919,   448,  9107,\n",
       "           226, 27477,  4458,  1921,  9017,   874,   428,  1477,  1291,   461,\n",
       "           396,   988,  9017,     6,   148,   148,    64,    25, 28853,  3494,\n",
       "           615,  1358,  1130,  5196,   483,    17,   148,   148,  1941,    58,\n",
       "           678,   103,   595,    71, 12030,   148,   148,   128,  2975,   493]])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding arguments(input, output)\n",
    "# num_embeddings: size of the vocab\n",
    "# embedding_dim: the size to which you want to embed. Reduce the input to\n",
    "embedding = nn.Embedding(vocab_size, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_output = embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200, 400])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape(batch, seq, feature)\n",
    "embedding_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Layer\n",
    "\n",
    "Put the embedding output into the lstm layer\n",
    "- parameters: input_size, hidden_size, num_layers, batch_first\n",
    "    - num of recurrent layers. Seting this to 2 stacks two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs from the first LSTM and computing the final results.\n",
    "    - batch_first: if true then the input and output tensors are provided as (batch, seq, feature)\n",
    "\n",
    "\n",
    "### Initializing the hidden state\n",
    "\n",
    "Zero initial hiddenstate is standard and this is the default if we dont pass in a hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=400, hidden_size=256, num_layers=2, batch_first=True, dropout=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing the hidden state to zeroes\n",
    "\n",
    "The hidden and cell state reset to zero for every epoch so you don't need to initialize them unless you are initializing them to something other than zero.\n",
    "\n",
    "Since I have n_layers equal to 2, the output is a packed sequence. So I need to unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output, hidden = lstm(embedding_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200, 256])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2082,  0.4071,  0.0266,  ..., -0.1071, -0.1440, -0.0391],\n",
       "          [-0.3084, -0.1051,  0.0173,  ...,  0.1882, -0.1369, -0.0421]],\n",
       " \n",
       "         [[-0.0206,  0.0158, -0.0287,  ...,  0.0335, -0.0180, -0.0492],\n",
       "          [-0.0426,  0.0082,  0.0173,  ...,  0.0759, -0.0195, -0.0333]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[-0.3053,  0.6159,  0.0494,  ..., -0.3238, -0.3394, -0.0859],\n",
       "          [-0.5425, -0.1814,  0.0623,  ...,  0.2383, -0.4649, -0.0806]],\n",
       " \n",
       "         [[-0.0391,  0.0354, -0.0598,  ...,  0.0774, -0.0354, -0.0970],\n",
       "          [-0.0794,  0.0153,  0.0434,  ...,  0.1414, -0.0426, -0.0596]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hidden = tuple([each.data for each in hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2082,  0.4071,  0.0266,  ..., -0.1071, -0.1440, -0.0391],\n",
       "          [-0.3084, -0.1051,  0.0173,  ...,  0.1882, -0.1369, -0.0421]],\n",
       " \n",
       "         [[-0.0206,  0.0158, -0.0287,  ...,  0.0335, -0.0180, -0.0492],\n",
       "          [-0.0426,  0.0082,  0.0173,  ...,  0.0759, -0.0195, -0.0333]]]),\n",
       " tensor([[[-0.3053,  0.6159,  0.0494,  ..., -0.3238, -0.3394, -0.0859],\n",
       "          [-0.5425, -0.1814,  0.0623,  ...,  0.2383, -0.4649, -0.0806]],\n",
       " \n",
       "         [[-0.0391,  0.0354, -0.0598,  ...,  0.0774, -0.0354, -0.0970],\n",
       "          [-0.0794,  0.0153,  0.0434,  ...,  0.1414, -0.0426, -0.0596]]]))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to pass the vector into the fully connected layer. The fc layer expects 1D vectors.\n",
    "In order to do that I need to flatten the vector -- the resulting shape is going to be (1, rowsxcols)\n",
    "so in this case is going to be (1, 50*200)\n",
    "\n",
    "\n",
    "If there is any situation that you don't know how many rows you want but are sure of the number of columns, then you can specify this with a -1. (Note that you can extend this to tensors with more dimensions. Only one of the axis value can be -1). This is a way of telling the library: \"give me a tensor that has these many columns and you compute the appropriate number of rows that is necessary to make this happen\".\n",
    "\n",
    "https://stackoverflow.com/questions/42479902/how-does-the-view-method-work-in-pytorch\n",
    "\n",
    "The view method returns a tensor with the same data as the self tensor (which means that the returned tensor has the same number of elements), but with a different shape. \n",
    "\n",
    "you have 10,000 elements each element is represented by 256\n",
    "The 256 are going to go to the linear and are going to make an output of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking\n",
    "lstm_output = lstm_output.contiguous().view(-1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 256])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm aware the LSTM cell uses both sigmoid and tanh activation functions internally, however when creating a stacked LSTM architecture does it make sense to pass their outputs through an activation function (e.g. ReLU)?\n",
    "\n",
    "https://stats.stackexchange.com/questions/444923/activation-function-between-lstm-layers\n",
    "\n",
    "Given that ReLUs can have quite large outputs, they have traditionally been regarded as inappropriate for use with LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a probability of dropout around 0.5 for hidden units and 0.2 for inputs worked well for a variety of tasks.\n",
    "\n",
    "The core concept of Srivastava el al. (2014) is that “each hidden unit in a neural network trained with dropout must learn to work with a randomly chosen sample of other units. This should make each hidden unit more robust and drive it towards creating useful features on its own without relying on other hidden units to correct its mistakes.”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0159, -0.0085,  0.0009,  ..., -0.0335, -0.0221,  0.0253],\n",
       "        [-0.0349, -0.0438, -0.0341,  ...,  0.0064, -0.0208, -0.0084],\n",
       "        [ 0.0294, -0.0283, -0.0673,  ..., -0.0264, -0.0305,  0.0291],\n",
       "        ...,\n",
       "        [ 0.0219,  0.0046,  0.0161,  ...,  0.1062, -0.0486, -0.0518],\n",
       "        [-0.0319, -0.0146,  0.0177,  ...,  0.0467, -0.0167, -0.0606],\n",
       "        [-0.0426,  0.0082,  0.0173,  ...,  0.0759, -0.0195, -0.0333]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout = nn.Dropout(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output_dropout = Dropout(lstm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 256])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output_dropout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000,  0.0000,  ..., -0.0419, -0.0276,  0.0316],\n",
       "        [-0.0436, -0.0000, -0.0000,  ...,  0.0080, -0.0260, -0.0000],\n",
       "        [ 0.0368, -0.0354, -0.0842,  ..., -0.0330, -0.0000,  0.0363],\n",
       "        ...,\n",
       "        [ 0.0273,  0.0000,  0.0201,  ...,  0.1327, -0.0608, -0.0000],\n",
       "        [-0.0398, -0.0182,  0.0221,  ...,  0.0584, -0.0209, -0.0758],\n",
       "        [-0.0533,  0.0103,  0.0216,  ...,  0.0949, -0.0244, -0.0416]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(256,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_output = fc(lstm_output_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1036],\n",
       "        [-0.0853],\n",
       "        [-0.0626],\n",
       "        [-0.1280]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_output[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a sigmoid function to trans the output to a probability value\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_output = sigmoid(fc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4741],\n",
       "        [0.4787],\n",
       "        [0.4844],\n",
       "        [0.4681]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_output[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_out = sigmoid_output.view(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4741],\n",
       "        [0.4787],\n",
       "        [0.4844],\n",
       "        [0.4681]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_output[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_output[:,-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding = nn.Embedding(vocab_size, 400)\n",
    "embedding_output = embedding(x)\n",
    "\n",
    "lstm = nn.LSTM(input_size=400, hidden_size=256, num_layers=2, batch_first=True, dropout=0.5)\n",
    "lstm_output, hidden = lstm(embedding_output)\n",
    "lstm_output = lstm_output.contiguous().view(-1, 256)\n",
    "\n",
    "Dropout = nn.Dropout(0.2)\n",
    "lstm_output_dropout = Dropout(lstm_output)\n",
    "\n",
    "fc = nn.Linear(256,1)\n",
    "fc_output = fc(lstm_output_dropout)\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "sigmoid_output = sigmoid(fc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_embeddings = vocab_size\n",
    "# embedding_dim = embedding_output = 400\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, batch_first, dropout=0.5, output_features=1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.dropout = dropout\n",
    "        self.output_features = output_features\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, dropout=0.5, batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_features)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        embedding_output = self.embedding(x)\n",
    "\n",
    "        lstm_output, hidden = self.lstm(embedding_output)\n",
    "        lstm_output = lstm_output.contiguous().view(-1, self.hidden_size)\n",
    "        lstm_output_dropout = self.dropout(lstm_output)\n",
    "\n",
    "        fc_output = self.fc(lstm_output_dropout)\n",
    "\n",
    "        sigmoid_output = self.sigmoid(fc_output)\n",
    "        \n",
    "        sigmoid_output = sigmoid_output.view(batch_size, -1)\n",
    "        sigmoid_output = sigmoid_output[:, -1]\n",
    "\n",
    "        return sigmoid_out, hidden\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if train_on_gpu:\n",
    "            hidden = (weight.new(self.num_layers, batch_size, self.hidden_size).zero_().cuda(),\n",
    "                     weight.new(self.num_layers, batch_size, self.hidden_size).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.num_layers, batch_size, self.hidden_size).zero_(),\n",
    "                     weight.new(self.num_layers, batch_size, self.hidden_size).zero_())\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = vocab_size + 1\n",
    "embedding_dim = 400\n",
    "hidden_size = 256\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(num_embeddings=num_embeddings, embedding_dim=embedding_dim, \n",
    "            hidden_size = hidden_size, num_layers= num_layers, output_features=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss and optimization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion= nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on GPU\n"
     ]
    }
   ],
   "source": [
    "if train_on_gpu:\n",
    "    print('training on GPU')\n",
    "else:\n",
    "    print('GPU is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(73920, 400)\n",
       "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passing the model to gpu\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "print_every = 100\n",
    "counter = 0\n",
    "clip = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target and input must have the same number of elements. target nelement (50) != input nelement (400)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-465-0ffa79398ec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2370\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2371\u001b[0m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[1;32m-> 2372\u001b[1;33m                          \"!= input nelement ({})\".format(target.numel(), input.numel()))\n\u001b[0m\u001b[0;32m   2373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (50) != input nelement (400)"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        counter += 1\n",
    "        if train_on_gpu:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            \n",
    "        #hidden = tuple([each.data for each in hidden])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output, hidden = model(x, hidden)\n",
    "        \n",
    "        loss = criterion(output, y.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            \n",
    "            val_hidden = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            \n",
    "            for x, y in valid_loader:\n",
    "                if train_on_gpu:\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "                \n",
    "                output, hidden = model(x, val_hidden)\n",
    "                val_loss = criterion(output.squeeze(), y.float())\n",
    "\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                \"Step: {}...\".format(counter),\n",
    "                \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding layer -> LSTM layer --> sigmoid\n",
    "# embedding layer: \n",
    "    # nn.Embedding\n",
    "        # Input: (LongTensor) (num_embeddings, embedding_dim)\n",
    "        # Output: input shape, embedding_dim\n",
    "# LSTM layer\n",
    "    # Input: (tensor w initial hidden state for each element in the batch,\n",
    "         # tensor w the initiall cell state for each elt in the batch)\n",
    "    # Output: (hidden state for t=seq length, cell state for t=seq_length)\n",
    "# sigmoid layer\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # super is used to execute a method in a parent class\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # self.embedding is a property of the module class of the type Embedding\n",
    "        # num_embeddings is the vocab size\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.long()\n",
    "        embedding_output = self.embedding(x)\n",
    "        #output, (hn, cn) = self.lstm(embedding_output, (h0, c0))\n",
    "        output, (hn, cn) = self.lstm(embedding_output, (h0, c0))\n",
    "        # the output is a packed sequence\n",
    "        # after padding, there is a lot more computation than necessary\n",
    "        # packing flattens the sequences (columns). The flattened version does not include the zeroes.\n",
    "        # I need to unpack the output\n",
    "        # THIS GIVES OUTPUTS of the shape (batch_size, lstm_size). You\n",
    "        # can use these directly for further input but if you want to use the inter\n",
    "        # mediate outputs as you need to unpack\n",
    "        output = output.view(seq_len, batch)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
