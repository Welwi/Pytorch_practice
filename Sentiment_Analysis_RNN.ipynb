{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model classifies movie reviews into positive and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from collections import Counter, OrderedDict\n",
    "import itertools\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deep-learning-v2-pytorch/sentiment-analysis-network/reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('deep-learning-v2-pytorch/sentiment-analysis-network/labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will recieve the imported reviews (ch by ch) and return \n",
    "def clean_text(text):\n",
    "    ''' This Function recieves reviews (ch by ch) and returns a list of\n",
    "    reviews without punctuation'''\n",
    "    # remove punctuation\n",
    "    s = ''.join(ch.lower() for ch in text if ch not in punctuation)\n",
    "    \n",
    "    # separate each review and add to a list so that I have a list of reviews\n",
    "    separated_reviews = []\n",
    "\n",
    "    for review in s.split('\\n'):\n",
    "        review = ''.join(review)\n",
    "        separated_reviews.append(review)\n",
    "        \n",
    "    return separated_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = clean_text(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clean_text(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewEncoder:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__words_dict = {}\n",
    "        self.__indexer = 1\n",
    "        \n",
    "    def word_dict(self):\n",
    "        '''This method returns the created dictionary'''\n",
    "        return self.__words_dict\n",
    "    \n",
    "    def encode(self, text):\n",
    "        '''Encodes the reviews'''\n",
    "        encoded_review = []\n",
    "        words = text.split()\n",
    "        #print(words)\n",
    "        for word in words:\n",
    "            if word in self. __words_dict:\n",
    "                encoded_review.append(self.__words_dict[word])\n",
    "            else:\n",
    "                self.__words_dict[word] = self.__indexer\n",
    "                self.__indexer += 1\n",
    "                encoded_review.append(self.__words_dict[word])\n",
    "        return encoded_review\n",
    "    \n",
    "    def len_dict(self):\n",
    "        '''Returns the length of the review'''\n",
    "        return len(self.__words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ReviewEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the reviews\n",
    "encoded_reviews = []\n",
    "for review in reviews:\n",
    "    encoded_reviews.append(encoder.encode(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing positive to be 1 and negative zero\n",
    "encoded_labels = []\n",
    "for label in labels:\n",
    "    if label == 'positive':\n",
    "        encoded_labels.append(1)\n",
    "    else:\n",
    "        encoded_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = encoder.len_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_reviews(list_of_reviews):\n",
    "    '''This function checks for empty reviews, returns the index\n",
    "    and drops them'''\n",
    "    full_reviews = []\n",
    "    index_to_remove = []\n",
    "    \n",
    "    for index, review in enumerate(list_of_reviews):\n",
    "        if len(review) != 0:\n",
    "            full_reviews.append(review)\n",
    "        else:\n",
    "            index_to_remove.append(index)\n",
    "    print('Indexes to remove from the labels: ', index_to_remove)\n",
    "    \n",
    "    return full_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes to remove from the labels:  [25000]\n"
     ]
    }
   ],
   "source": [
    "reviews = drop_empty_reviews(encoded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove label with index 25000\n",
    "del encoded_labels[25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_truncation(encoded_review_list, seq_length):\n",
    "    '''This function addes zeroes to the left of a review if\n",
    "    it is shorter than the seq_length and truncates reviews\n",
    "    longer than the seq_length\n",
    "    This step is important because the dataloader expects all\n",
    "    of the reviews to be of the same size'''\n",
    "    \n",
    "    padded_review = []\n",
    "    for review in encoded_review_list:\n",
    "        if len(review) < seq_length:\n",
    "            padding = seq_length - len(review)\n",
    "            review = ([0]*padding + review)\n",
    "            padded_review.append(review)\n",
    "        elif len(review) > seq_length:\n",
    "            review = review[:seq_length]\n",
    "            padded_review.append(review)\n",
    "        else:\n",
    "            padded_review.append(review)\n",
    "            \n",
    "    return padded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_reviews = padding_truncation(reviews, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the type of the padded reviews from list to an array of type int\n",
    "padded_reviews = np.asarray(padded_reviews, dtype=int)\n",
    "encoded_labels = np.asarray(encoded_labels, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the training, validation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = int(len(padded_reviews) * 0.8)\n",
    "validation = int(training + len(padded_reviews)*0.1)\n",
    "\n",
    "train_x = padded_reviews[:training]\n",
    "train_y = np.array(encoded_labels[:training])\n",
    "\n",
    "val_x = padded_reviews[training:validation]\n",
    "val_y = np.array(encoded_labels[training:validation])\n",
    "\n",
    "test_x = padded_reviews[validation:]\n",
    "test_y = np.array(encoded_labels[validation:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_dataset = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_dataset = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=50, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Layer\n",
    "\n",
    "Put the embedding output into the lstm layer\n",
    "- parameters: input_size, hidden_size, num_layers, batch_first\n",
    "    - num of recurrent layers. Seting this to 2 stacks two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs from the first LSTM and computing the final results.\n",
    "    - batch_first: if true then the input and output tensors are provided as (batch, seq, feature)\n",
    "\n",
    "\n",
    "### Initializing the hidden state\n",
    "\n",
    "Zero initial hiddenstate is standard and this is the default if we dont pass in a hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing the hidden state to zeroes\n",
    "\n",
    "The hidden and cell state reset to zero for every epoch so you don't need to initialize them unless you are initializing them to something other than zero.\n",
    "\n",
    "Since I have n_layers equal to 2, the output is a packed sequence. So I need to unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to pass the vector into the fully connected layer. The fc layer expects 1D vectors.\n",
    "In order to do that I need to flatten the vector -- the resulting shape is going to be (1, rowsxcols)\n",
    "so in this case is going to be (1, 50*200)\n",
    "\n",
    "\n",
    "If there is any situation that you don't know how many rows you want but are sure of the number of columns, then you can specify this with a -1. (Note that you can extend this to tensors with more dimensions. Only one of the axis value can be -1). This is a way of telling the library: \"give me a tensor that has these many columns and you compute the appropriate number of rows that is necessary to make this happen\".\n",
    "\n",
    "https://stackoverflow.com/questions/42479902/how-does-the-view-method-work-in-pytorch\n",
    "\n",
    "The view method returns a tensor with the same data as the self tensor (which means that the returned tensor has the same number of elements), but with a different shape. \n",
    "\n",
    "you have 10,000 elements each element is represented by 256\n",
    "The 256 are going to go to the linear and are going to make an output of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm aware the LSTM cell uses both sigmoid and tanh activation functions internally, however when creating a stacked LSTM architecture does it make sense to pass their outputs through an activation function (e.g. ReLU)?\n",
    "\n",
    "https://stats.stackexchange.com/questions/444923/activation-function-between-lstm-layers\n",
    "\n",
    "Given that ReLUs can have quite large outputs, they have traditionally been regarded as inappropriate for use with LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a probability of dropout around 0.5 for hidden units and 0.2 for inputs worked well for a variety of tasks.\n",
    "\n",
    "The core concept of Srivastava el al. (2014) is that “each hidden unit in a neural network trained with dropout must learn to work with a randomly chosen sample of other units. This should make each hidden unit more robust and drive it towards creating useful features on its own without relying on other hidden units to correct its mistakes.”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding = nn.Embedding(vocab_size, 400)\n",
    "embedding_output = embedding(x)\n",
    "\n",
    "lstm = nn.LSTM(input_size=400, hidden_size=256, num_layers=2, batch_first=True, dropout=0.5)\n",
    "lstm_output, hidden = lstm(embedding_output)\n",
    "lstm_output = lstm_output.contiguous().view(-1, 256)\n",
    "\n",
    "Dropout = nn.Dropout(0.2)\n",
    "lstm_output_dropout = Dropout(lstm_output)\n",
    "\n",
    "fc = nn.Linear(256,1)\n",
    "fc_output = fc(lstm_output_dropout)\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "sigmoid_output = sigmoid(fc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print('Training on GPU')\n",
    "else:\n",
    "    print('GPU not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, drop_prob, out_features):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_features = out_features\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, dropout = drop_prob)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_size, out_features)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        embedding_out = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embedding_out, hidden)\n",
    "\n",
    "        lstm_out = lstm_out.contiguous().view(-1, 256)\n",
    "\n",
    "        lstm_out_dropout = self.dropout(lstm_out)\n",
    "        \n",
    "        fc_out = self.fc(lstm_out_dropout)\n",
    "\n",
    "        sig_out = self.sigmoid(fc_out)\n",
    "    \n",
    "        \n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:,-1]\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.num_layers, batch_size, self.hidden_size).zero_().cuda(),\n",
    "                  weight.new(self.num_layers, batch_size, self.hidden_size).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.num_layers, batch_size, self.hidden_size).zero_(),\n",
    "                      weight.new(self.num_layers, batch_size, self.hidden_size).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = 74072 + 1\n",
    "batch_size = 50\n",
    "embedding_dim = 400\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "drop_prob = 0.5\n",
    "out_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(num_embeddings = num_embeddings, embedding_dim = embedding_dim, hidden_size = hidden_size, \n",
    "            num_layers = num_layers, drop_prob = drop_prob, out_features = out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(74073, 400)\n",
       "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "epochs = 4\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.693491... Val Loss: 0.686222\n",
      "Epoch: 1/4... Step: 200... Loss: 0.674710... Val Loss: 0.642303\n",
      "Epoch: 1/4... Step: 300... Loss: 0.545069... Val Loss: 0.615143\n",
      "Epoch: 1/4... Step: 400... Loss: 0.681781... Val Loss: 0.538172\n",
      "Epoch: 2/4... Step: 500... Loss: 0.459832... Val Loss: 0.634001\n",
      "Epoch: 2/4... Step: 600... Loss: 0.493618... Val Loss: 0.493223\n",
      "Epoch: 2/4... Step: 700... Loss: 0.571743... Val Loss: 0.452888\n",
      "Epoch: 2/4... Step: 800... Loss: 0.416146... Val Loss: 0.454839\n",
      "Epoch: 3/4... Step: 900... Loss: 0.227714... Val Loss: 0.480114\n",
      "Epoch: 3/4... Step: 1000... Loss: 0.300825... Val Loss: 0.453474\n",
      "Epoch: 3/4... Step: 1100... Loss: 0.307104... Val Loss: 0.439663\n",
      "Epoch: 3/4... Step: 1200... Loss: 0.297350... Val Loss: 0.423074\n",
      "Epoch: 4/4... Step: 1300... Loss: 0.438367... Val Loss: 0.456411\n",
      "Epoch: 4/4... Step: 1400... Loss: 0.220592... Val Loss: 0.421826\n",
      "Epoch: 4/4... Step: 1500... Loss: 0.258635... Val Loss: 0.435854\n",
      "Epoch: 4/4... Step: 1600... Loss: 0.381751... Val Loss: 0.437448\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    h = model.init_hidden(batch_size)\n",
    "    for x, y in train_loader:\n",
    "        counter += 1\n",
    "        \n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        x = x.long()\n",
    "        \n",
    "        h = tuple([each.data for each in h])\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output, hidden = model(x, h)\n",
    "\n",
    "        loss = criterion(output.squeeze(), y.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            \n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for x, y in valid_loader:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                x = x.long()\n",
    "                \n",
    "                val_h = tuple([each.data for each in h])\n",
    "                \n",
    "                output, val_h = model(x, val_h)\n",
    "                val_loss = criterion(output.squeeze(), y.float())\n",
    "                \n",
    "                val_losses.append(val_loss.item())\n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.519\n",
      "Test accuracy: 0.782\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "for x, y in test_loader:\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "    x = x.long()\n",
    "    \n",
    "    h = tuple([each.data for each in h])\n",
    "    \n",
    "    output, h = model(x, h)\n",
    "    test_loss = criterion(output.squeeze(), y.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    pred = torch.round(output.squeeze())\n",
    "    \n",
    "    correct_tensor = pred.eq(y.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "    \n",
    "    \n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, test_review, sequence_length=200):\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    # tokenize review\n",
    "    test_ints = encoder.encode(test_review)\n",
    "    #test_ints = tokenize_review(test_review)\n",
    "    \n",
    "    # pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    #features = padding_truncation(test_ints)\n",
    "    #features = pad_features(test_ints, seq_length)\n",
    "    features = []\n",
    "    if len(test_ints) < 200:\n",
    "        padding = 200 - len(test_ints)\n",
    "        features = ([0]*padding + test_ints)\n",
    "    \n",
    "    # convert to tensor to pass into your model\n",
    "    features = np.array(features)\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    feature_tensor = feature_tensor.unsqueeze(0)\n",
    "    \n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    \n",
    "    # get the output from the model\n",
    "    output, h = net(feature_tensor.long(), h)\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze()) \n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    \n",
    "    # print custom response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Positive review detected!\")\n",
    "    else:\n",
    "        print(\"Negative review detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.051283\n",
      "Negative review detected.\n",
      "Prediction value, pre-rounding: 0.962218\n",
      "Positive review detected!\n"
     ]
    }
   ],
   "source": [
    "test_review_pos = 'This movie had the best acting and the dialogue was so good. I loved it.'\n",
    "test_review_neg = 'This movie had the wrost acting and the dialogue was bad.'\n",
    "\n",
    "\n",
    "# call function\n",
    "seq_length=200 # good to use the length that was trained on\n",
    "\n",
    "predict(model, test_review_neg, seq_length)\n",
    "predict(model, test_review_pos, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
