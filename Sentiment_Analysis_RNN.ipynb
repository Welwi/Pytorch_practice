{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from collections import Counter, OrderedDict\n",
    "import itertools\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deep-learning-v2-pytorch/sentiment-analysis-network/reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('deep-learning-v2-pytorch/sentiment-analysis-network/labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will recieve the imported reviews (ch by ch) and return \n",
    "def clean_text(text):\n",
    "    ''' This Function recieves reviews (ch by ch) and returns a list of\n",
    "    reviews without punctuation'''\n",
    "    # remove punctuation\n",
    "    s = ''.join(ch.lower() for ch in text if ch not in punctuation)\n",
    "    \n",
    "    # separate each review and add to a list so that I have a list of reviews\n",
    "    separated_reviews = []\n",
    "\n",
    "    for review in s.split('\\n'):\n",
    "        review = ''.join(review)\n",
    "        separated_reviews.append(review)\n",
    "        \n",
    "    return separated_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = clean_text(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clean_text(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewEncoder:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__words_dict = {}\n",
    "        self.__indexer = 1\n",
    "        \n",
    "    def word_dict(self):\n",
    "        '''This method returns the created dictionary'''\n",
    "        return self.__words_dict\n",
    "    \n",
    "    def encode(self, text):\n",
    "        '''Encodes the reviews'''\n",
    "        encoded_review = []\n",
    "        words = text.split()\n",
    "        #print(words)\n",
    "        for word in words:\n",
    "            if word in self. __words_dict:\n",
    "                encoded_review.append(self.__words_dict[word])\n",
    "            else:\n",
    "                self.__words_dict[word] = self.__indexer\n",
    "                self.__indexer += 1\n",
    "                encoded_review.append(self.__words_dict[word])\n",
    "        return encoded_review\n",
    "    \n",
    "    def len_dict(self):\n",
    "        '''Returns the length of the review'''\n",
    "        return len(self.__words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ReviewEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the reviews\n",
    "encoded_reviews = []\n",
    "for review in reviews:\n",
    "    encoded_reviews.append(encoder.encode(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing positive to be 1 and negative zero\n",
    "encoded_labels = []\n",
    "for label in labels:\n",
    "    if label == 'positive':\n",
    "        encoded_labels.append(1)\n",
    "    else:\n",
    "        encoded_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = encoder.len_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_reviews(list_of_reviews):\n",
    "    '''This function checks for empty reviews, returns the index\n",
    "    and drops them'''\n",
    "    full_reviews = []\n",
    "    index_to_remove = []\n",
    "    \n",
    "    for index, review in enumerate(list_of_reviews):\n",
    "        if len(review) != 0:\n",
    "            full_reviews.append(review)\n",
    "        else:\n",
    "            index_to_remove.append(index)\n",
    "    print('Indexes to remove from the labels: ', index_to_remove)\n",
    "    \n",
    "    return full_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes to remove from the labels:  [25000]\n"
     ]
    }
   ],
   "source": [
    "reviews = drop_empty_reviews(encoded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove label with index 25000\n",
    "del encoded_labels[25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_truncation(encoded_review_list, seq_length):\n",
    "    '''This function addes zeroes to the left of a review if\n",
    "    it is shorter than the seq_length and truncates reviews\n",
    "    longer than the seq_length'''\n",
    "    \n",
    "    padded_review = []\n",
    "    for review in encoded_review_list:\n",
    "        if len(review) < seq_length:\n",
    "            padding = seq_length - len(review)\n",
    "            review = ([0]*padding + review)\n",
    "            padded_review.append(review)\n",
    "        elif len(review) > seq_length:\n",
    "            review = review[:seq_length]\n",
    "            padded_review.append(review)\n",
    "        else:\n",
    "            padded_review.append(review)\n",
    "            \n",
    "    return padded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_reviews = padding_truncation(reviews, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the type of the padded reviews from list to an array of type int\n",
    "padded_reviews = np.asarray(padded_reviews, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing labels from list to array of type int\n",
    "encoded_labels = np.asarray(encoded_labels, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(encoded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = drop_empty_reviews(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pad_features(test, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_reviews = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training, validation and testing sets\n",
    "\n",
    "training = int(len(padded_reviews) * 0.8)\n",
    "validation = int(training + len(padded_reviews)*0.1)\n",
    "\n",
    "train_x = padded_reviews[:training]\n",
    "train_y = np.array(encoded_labels[:training])\n",
    "\n",
    "val_x = padded_reviews[training:validation]\n",
    "val_y = np.array(encoded_labels[training:validation])\n",
    "\n",
    "test_x = padded_reviews[validation:]\n",
    "test_y = np.array(encoded_labels[validation:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_loader = DataLoader(dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    sampler=None,\n",
    "    batch_sampler=None,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    "    timeout=0,\n",
    "    worker_init_fn=None,\n",
    "    multiprocessing_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = np.array(encoded_labels[:split_idx]), np.array(encoded_labels[split_idx:])\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_dataset = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_dataset = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=50, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing\n",
    "\n",
    "testing = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = next(iter(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in testing:\n",
    "    x = x.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding arguments(input, output)\n",
    "# num_embeddings: size of the vocab\n",
    "# embedding_dim: the size to which you want to embed. Reduce the input to\n",
    "vocab_size = 73919\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_output = embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape(batch, seq, feature)\n",
    "embedding_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Layer\n",
    "\n",
    "Put the embedding output into the lstm layer\n",
    "- parameters: input_size, hidden_size, num_layers, batch_first\n",
    "    - num of recurrent layers. Seting this to 2 stacks two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs from the first LSTM and computing the final results.\n",
    "    - batch_first: if true then the input and output tensors are provided as (batch, seq, feature)\n",
    "\n",
    "\n",
    "### Initializing the hidden state\n",
    "\n",
    "Zero initial hiddenstate is standard and this is the default if we dont pass in a hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=400, hidden_size=256, num_layers=2, batch_first=True, dropout=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing the hidden state to zeroes\n",
    "\n",
    "The hidden and cell state reset to zero for every epoch so you don't need to initialize them unless you are initializing them to something other than zero.\n",
    "\n",
    "Since I have n_layers equal to 2, the output is a packed sequence. So I need to unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output, hidden = lstm(embedding_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hidden = tuple([each.data for each in hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to pass the vector into the fully connected layer. The fc layer expects 1D vectors.\n",
    "In order to do that I need to flatten the vector -- the resulting shape is going to be (1, rowsxcols)\n",
    "so in this case is going to be (1, 50*200)\n",
    "\n",
    "\n",
    "If there is any situation that you don't know how many rows you want but are sure of the number of columns, then you can specify this with a -1. (Note that you can extend this to tensors with more dimensions. Only one of the axis value can be -1). This is a way of telling the library: \"give me a tensor that has these many columns and you compute the appropriate number of rows that is necessary to make this happen\".\n",
    "\n",
    "https://stackoverflow.com/questions/42479902/how-does-the-view-method-work-in-pytorch\n",
    "\n",
    "The view method returns a tensor with the same data as the self tensor (which means that the returned tensor has the same number of elements), but with a different shape. \n",
    "\n",
    "you have 10,000 elements each element is represented by 256\n",
    "The 256 are going to go to the linear and are going to make an output of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking\n",
    "lstm_output = lstm_output.contiguous().view(-1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm aware the LSTM cell uses both sigmoid and tanh activation functions internally, however when creating a stacked LSTM architecture does it make sense to pass their outputs through an activation function (e.g. ReLU)?\n",
    "\n",
    "https://stats.stackexchange.com/questions/444923/activation-function-between-lstm-layers\n",
    "\n",
    "Given that ReLUs can have quite large outputs, they have traditionally been regarded as inappropriate for use with LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a probability of dropout around 0.5 for hidden units and 0.2 for inputs worked well for a variety of tasks.\n",
    "\n",
    "The core concept of Srivastava el al. (2014) is that “each hidden unit in a neural network trained with dropout must learn to work with a randomly chosen sample of other units. This should make each hidden unit more robust and drive it towards creating useful features on its own without relying on other hidden units to correct its mistakes.”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout = nn.Dropout(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output_dropout = Dropout(lstm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output_dropout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(256,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_output = fc(lstm_output_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a sigmoid function to trans the output to a probability value\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_output = sigmoid(fc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_output[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_out = sigmoid_output.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_output[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_output[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding = nn.Embedding(vocab_size, 400)\n",
    "embedding_output = embedding(x)\n",
    "\n",
    "lstm = nn.LSTM(input_size=400, hidden_size=256, num_layers=2, batch_first=True, dropout=0.5)\n",
    "lstm_output, hidden = lstm(embedding_output)\n",
    "lstm_output = lstm_output.contiguous().view(-1, 256)\n",
    "\n",
    "Dropout = nn.Dropout(0.2)\n",
    "lstm_output_dropout = Dropout(lstm_output)\n",
    "\n",
    "fc = nn.Linear(256,1)\n",
    "fc_output = fc(lstm_output_dropout)\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "sigmoid_output = sigmoid(fc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_embeddings = vocab_size\n",
    "# embedding_dim = embedding_output = 400\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, batch_first, dropout=0.5, output_features=1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.dropout = dropout\n",
    "        self.output_features = output_features\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, dropout=0.5, batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_features)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        x = x.long()\n",
    "        embedding_output = self.embedding(x)\n",
    "\n",
    "        lstm_output, hidden = self.lstm(embedding_output)\n",
    "        lstm_output = lstm_output.contiguous().view(-1, self.hidden_size)\n",
    "        lstm_output_dropout = self.dropout(lstm_output)\n",
    "\n",
    "        fc_output = self.fc(lstm_output_dropout)\n",
    "\n",
    "        sigmoid_output = self.sigmoid(fc_output)\n",
    "        \n",
    "        sigmoid_output = sigmoid_output.view(batch_size, -1)\n",
    "        sigmoid_output = sigmoid_output[:, -1]\n",
    "\n",
    "        return sigmoid_output, hidden\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if train_on_gpu:\n",
    "            hidden = (weight.new(self.num_layers, batch_size, self.hidden_size).zero_().cuda(),\n",
    "                     weight.new(self.num_layers, batch_size, self.hidden_size).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.num_layers, batch_size, self.hidden_size).zero_(),\n",
    "                     weight.new(self.num_layers, batch_size, self.hidden_size).zero_())\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 73919\n",
    "num_embeddings = vocab_size + 1\n",
    "embedding_dim = 400\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(num_embeddings=num_embeddings, embedding_dim=embedding_dim, \n",
    "            hidden_size = hidden_size, num_layers= num_layers, output_features=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss and optimization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion= nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    print('training on GPU')\n",
    "else:\n",
    "    print('GPU is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the model to gpu\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "print_every = 100\n",
    "counter = 0\n",
    "clip = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        counter += 1\n",
    "        if train_on_gpu:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            \n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output, hidden = model(x, hidden)\n",
    "        \n",
    "        loss = criterion(output.squeeze(), y.float().squeeze())\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            \n",
    "            val_hidden = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            \n",
    "            for x, y in valid_loader:\n",
    "                if train_on_gpu:\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "                    \n",
    "                output, hidden = model(x, val_hidden)\n",
    "                #print(output.shape)\n",
    "                #print(y.float().shape)\n",
    "                val_loss = criterion(output.squeeze(), y.float().squeeze())\n",
    "\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                \"Step: {}...\".format(counter),\n",
    "                \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                  print(val_losses),\n",
    "                \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = 74072 + 1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
